---
title:  "한눈에 보는 머신러닝"
excerpt: "핸즈온 머신러닝 1.1장 내용 정리"

categories:
  - study
tags:
  - Study
  - MachineLearning
  - Dataanalysis
---

# 1장. 한눈에 보는 머신러닝
{:.no_toc}
> 이 챕터는 머신러닝의 개요와, 모델의 종류, 그리고 워크플로우에 대해 다룬다.

**목차**

{:toc}
## 머신러닝이란?

- 책에서 소개하는 머신러닝은,
    - 특정 작업의 성능을 올리기 위해, 데이터로 학습되도록 프로그래밍 하는 것
- 나의 언어로 조금 바꾼 머신러닝은,
    - 문제 해결을 위해 데이터로 기계를 학습시키는 것

### 왜 요즘 다들 머신러닝 머신러닝 하는가?

- 크게 두 가지 이유가 있다.
    1. 효율성
        - 사람이 하면 오래 걸리는 것들을 **빠르게** 처리할 수 있다.
        - 유지보수가 용이하다.
        - 정확도를 높일 수 있다.
        - 복잡한 문제를 비교적 쉽게 해결할 수 있다.
    2. 분석
        - 모르고있던 인사이트를 얻을 수 있다.
        - 모델이 학습한 것을 조사하며 모르던 패턴을 발견할 수도 있다.
        - 이러한 것을 **데이터 마이닝(data mining)**이라고 한다.

## 사례

- 책에 나온 사례 중 인상적인 사례는 아래와 같다.
    - 뇌를 스캔하여 종양 진단하기: 시맨틱 분할 작업
    - 구매 이력 기반으로 고객을 나누고, 각 그룹마다 다른 마케팅 전략 수립: 군집
    - 고차원의 복잡한 데이터를 의미있는 그래프로 표현하기: 시각화
    - 과거 구매 이력을 기반으로 상품 추천하기: 추천 시스템
- 내가 관심있는 주제들은 이렇다.
    - 방문, 수익 등과 같은 지표 예측
    - 고객 군집을 통한 특성 파악, 전략 수립
        - 공부했지만 아직도 많이 어려운 비지도학습

    - 데이터 시각화
    - 추천 시스템 구현
        - 이를 위해 선형대수를 공부하고있다..

## 머신러닝 시스템의 종류

- 크게 세 범주로 나뉜다.
    - 사람의 감독 여부
    - 실시간 여부
    - 사례 기반인지, 모델 기반인지

### 1-1) **지도학습**

- 레이블(원하는 답)이 같이 주어진다.
- 분류와 회귀가 대표적이다.
- 분류
    - 분류 클래스가 주어지고, 새로운 데이터가 어떤 클래스인지 예측한다.
    - 가장 대표적으로 스팸메일! 아니면 캐글의 타이타닉 생존 예측!
    - 주어지는 목표 벡터는 범주형 데이터
- 회귀
    - 연속 데이터가 레이블로 주어지고, 새로운 값이 어떤 값을 취할 지 예측
    - 중고차 가격 예측이나 부동산 가격 예측 등이 여기에 속한다.

### 1-2) 비지도학습

- 레이블 없이 알고리즘이 스스로 학습
- 군집
    - 스스로 어떤 특성에 의거하여 유사한 그룹끼리 그루핑
    - 예를 들어, 위에서 언급한 고객 군집 (을 통한 특성 파악)
    - 다만, 비지도이다보니 어떻게 군집될 지 모른다.
        - 사진을 예로 들면, 나는 옆모습과 앞모습을 구별하고 싶은데,
        - 모델은 남성과 여성으로 구별하는 등..
- 시각화
    - 데이터가 어떻게 조직되어있는지 알 수 있다.
- 특이값 탐지
    - 아웃라이어 탐지, 특이치 탐지 등 대표성이 떨어지는 값들을 추려낸다.
        - 아웃라이어 탐지는 섞여있는 샘플에서 아웃라이어를 탐지하는 반면,
        - 특이치 탐지는 정상 샘플들로만 학습해야한다. 아웃라이어도 함께 섞여있으면, 추후에 아웃라이어도 정상 샘플이라고 인지한다.
- 연관규칙 학습
    - 특성 간 관계를 찾아준다.

### 1-3) 준지도학습

- 주로 비지도+지도 와 같이 짬뽕된 버전
- 대부분 레이블링이 안 되어있고, 소수만 레이블이 되어있는 데이터
- 적용 사례를 들자면,
    - 구글 포토 호스팅이 있다.
    - 인물 사진이 매우 많고, 몇 개의 인물 사진에만 이름 태그를 달아놓으면,
    - 자동으로 레이블하지 않은 사진도 누구인지 인식해줌

### 1-4) 강화학습

- 행동에 따른 보상(벌점)을 최대화(최소화)시키는 행동을 찾기 위해 학습하는 것
- 예를 들면 똥피하기 게임
- 환경 관찰 → 행동 → 보상(or벌점) → 큰 보상을 위해 학습 → 환경 관찰 → ....
- 위와 같은 시스템을 에이전트라고 한다.

### 2-1) 배치학습

- 오프라인 학습, 실시간 학습 아님
- 가용한 데이터를 모두 사용하여 학습시킴, 간단하고 잘 동작
- 하지만 많은 컴퓨터자원을 필요로 함
    - 제한된 시스템(스마트폰 등)에서 많은 양의 훈련데이터가 왔다갔다하면 치명적!
- 업데이트를 위한 자동화는 가능하다.

### 2-2) 온라인학습

- 실시간으로 학습, 동향이 중요한 문제에서 쓰임
    - 예를 들면 주식과 같은
- 스스로 학습하고, 컴퓨터 자원 제약에 대한 부담이 없다.
- 외부메모리란?
    - 큰 데이터셋을 학습할 때, 오프라인 환경에서 조금씩 데이터를 분할하여 학습
    - 온라인이라는 말이 무색하긴 한데, 점진적 학습이라고 이해하면 편하다.
- 학습률
    - 새로운 데이터를 얼마나 잘 학습할 지에 대한 설정
    - 높으면
        - 새로운 데이터에 잘 적응하지만,
        - 아웃라이어의 영향을 많이 받을 수 있고
        - 기존 데이터 손실 위험이 있다.
    - 낮으면
        - 아웃라이어의 영향에서 비교적 자유롭고
        - 기존 데이터에 대한 손실이 적지만
        - 새로운 것에 대한 학습이 느리다.

### 3-1) 사례 기반 학습

- 데이터들을 기억하고있다가, 새로운 값이 오면 기존 값 중 비슷한 것으로 예측하는 것
- 비슷한지 안 비슷한지 알기 위해, **유사도 측정** 이라는 것을 해야한다.
    - 예를들어, 스팸메일에서는 스팸메일에 있는 단어들을 다 기억해버려서
    - 단어의 등장 수가 유사하면 유사도가 높다든지 등

### 3-2) 모델 기반 학습

- 데이터로부터 모델을 만들어서 예측에 사용하는 것
- 선형 회귀를 예로 들면,
    - 데이터로 선형 모델을 만들고,
    - 모델이 훈련 데이터를 잘 반영하는지 비용 함수(혹은 효용 함수)를 정의하고,
    - 이를 최소화하는(혹은 최대화하는) 모델을 찾음
    - 훈련된 모델을 통해 새로운 데이터를 예측

## 머신러닝의 주요 도전 과제

- 머신러닝을 위해서는 두가지가 필요하다.
    - 데이터와 알고리즘
- 그러므로 당연히, 머신러닝이 해결해야할 도전 과제는
    - 나쁜 데이터와 나쁜 알고리즘이다.

### 과제 1) 충분하지 않은 양의 데이터

- 복잡한 문제일수록 많은 데이터가 필요하다.
- 불충분하면 성능이 떨어질 수 있다.
- 특히 데이터가 적으면 오버피팅될 가능성이 높다.

### 과제 2) 대표성이 없는 데이터

- 대표성이 없으면 당연히 성능도 떨어진다.
- 데이터가 적으면 샘플링 잡음이 생긴다.
    - 대표성 없는 데이터가 많이 혼재된다.
- 데이터가 많더라도 표본 추출이 잘못된다면 샘플링 편향이 발생한다.
    - 일례로, 쇼핑몰에서 다음과같은 실수가 빈번히 일어난다.
    - 우리의 고객이 남긴 후기를 분석하면 모든 고객의 의견을 알 수 있다! 라는 실수
        - 후기를 남기는 고객의 비율이 적을 뿐더러,
        - 후기를 남기는 것이 충성고객의 특징이 아닌지 점검해봐야한다.

### 과제 3) 낮은 품질의 데이터

- 다수의 아웃라이어나 결측값이 포함되어있으면 성능이 낮아진다.
- 아웃라이어는 적절하게 배제하고,
- 결측값은 상황에 맞게 대표값으로 채우거나 삭제하는 것이 좋다.

### 과제 4) 관련 없는 데이터

- garbage in, garbage out!
- 필요없는 특성은 버리고,
- 적절한 피처셀렉션, 피처 추출 등 피처엔지니어링을 통해 모델의 성능을 올려야한다.

### 과제 5) 과대적합

- 훈련 세트에만 잘 맞고, 일반화가 잘 안됨
    - 일반화: 훈련된 모델이 새로운 데이터에도 좋은 성능을 보이는가?
- 각종 규제가 있는 모델(Ridge, Lasso 등)을 사용하거나, 하이퍼파라미터 튜닝을 통해 규제해야함

### 과제 6) 과소적합

- 모델이 너무 단순해서, 제대로 학습하지 못한 경우
- 모델 파라미터가 더 많은, 강력한 모델을 선택하거나,
- 피처 엔지니어링을 통해 더 좋은 피처를 제공하거나,
- 모델의 제약을 완화하는 방법으로 해결 가능

## 테스트와 검증

- 모델을 만들고, 잘 적응될 것이라고 운에 맡기면 안 된다.
- 훈련 데이터로 모델을 피팅하고, 테스트 세트로 검증을 하면 일반화 성능을 알아볼 수 있다.
- 이 과정에서 일반화 오차와 훈련 오차를 비교해볼 수 있다.

### 하이퍼파라미터 튜닝과 모델 선택

- 하이퍼파라미터 튜닝을 하기 위해, 훈련 세트도 [훈련세트, 검증세트]로 나누어야한다.
- 검증세트로 하이퍼파라미터를 조정하고, 테스트세트로는 모델의 일반화 성능을 알아본다.
- 이 과정에서 교차 검증을 통해 정확한 평가를 할 수 있다.

---

**챕터** **리뷰**

- 대부분 한 번 공부했던 내용이라, 가볍게 볼 수 있었다.
- 다만, 강화학습은 이름만 알고있었는데 가볍게 개념을 알 수 있었고,
- 온라인학습, 배치학습은 아예 처음 들어본 것이라서 새롭게 공부할 수 있었다.
